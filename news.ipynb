{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Load Libraries and Dataset\n"
      ],
      "metadata": {
        "id": "k1m2N77eKAZK"
      },
      "id": "k1m2N77eKAZK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4b8f86d",
      "metadata": {
        "id": "c4b8f86d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import TFBertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yqNcrZIiYoEX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqNcrZIiYoEX",
        "outputId": "215ca358-43f2-4420-8c0d-7270ca2361e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to load data by reading the first 14900 rows...\n",
            "Failed to load Fake.csv even with robust settings: read_csv() got an unexpected keyword argument 'error_bad_lines'\n",
            "Fake.csv loaded successfully using nrows=3800 workaround.\n",
            "True.csv loaded successfully by reading only the first 14900 rows.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define a safe number of rows to read.\n",
        "# We'll stop a little before the reported error row (14939) to be safe.\n",
        "SAFE_ROWS_TO_READ = 14900\n",
        "\n",
        "print(f\"Attempting to load data by reading the first {SAFE_ROWS_TO_READ} rows...\")\n",
        "\n",
        "# Load the first file (Fake.csv) using a highly robust method,\n",
        "# assuming it was the file with the previous errors, to ensure it loads.\n",
        "try:\n",
        "    # Use the Python engine and skip any previous known bad line (if any)\n",
        "    fake_df = pd.read_csv(\"/content/Fake.csv\", engine='python', error_bad_lines=False)\n",
        "    print(\"Fake.csv loaded successfully (potentially skipping bad lines).\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load Fake.csv even with robust settings: {e}\")\n",
        "    # Fallback to the known nrows fix if needed\n",
        "    try:\n",
        "        fake_df = pd.read_csv(\"/content/Fake.csv\", nrows=3800)\n",
        "        print(\"Fake.csv loaded successfully using nrows=3800 workaround.\")\n",
        "    except Exception:\n",
        "        print(\"Failed to load Fake.csv.\")\n",
        "\n",
        "# Load the second file (True.csv) by stopping before the EOF error row\n",
        "try:\n",
        "    true_df = pd.read_csv(\"/content/True.csv\", nrows=SAFE_ROWS_TO_READ)\n",
        "    print(f\"True.csv loaded successfully by reading only the first {SAFE_ROWS_TO_READ} rows.\")\n",
        "\n",
        "except Exception as e:\n",
        "    # This might happen if the file is smaller than 14900 rows or has another issue\n",
        "    print(f\"Failed to load True.csv using nrows. Trying without nrows: {e}\")\n",
        "    try:\n",
        "        true_df = pd.read_csv(\"/content/True.csv\", engine='python', error_bad_lines=False)\n",
        "        print(\"True.csv loaded successfully with robust engine.\")\n",
        "    except Exception as e_final:\n",
        "        print(f\"Final attempt failed for True.csv: {e_final}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering\n"
      ],
      "metadata": {
        "id": "174EYUExKMh9"
      },
      "id": "174EYUExKMh9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "206dae32",
      "metadata": {
        "id": "206dae32"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# # Load the datasets\n",
        "# try:\n",
        "#     fake_df = pd.read_csv(\"/content/Fake.csv\")\n",
        "#     true_df = pd.read_csv(\"/content/True.csv\")\n",
        "#     print(\"Files loaded successfully.\")\n",
        "# except FileNotFoundError as e:\n",
        "#     print(f\"Error: One of the files was not found. {e}\")\n",
        "#     # Handle error or exit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecf5be6c",
      "metadata": {
        "id": "ecf5be6c"
      },
      "outputs": [],
      "source": [
        "# Add a 'label' column to each DataFrame\n",
        "fake_df['label'] = 1  # 1 for fake news\n",
        "true_df['label'] = 0   # 0 for true news"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23307cb1",
      "metadata": {
        "id": "23307cb1"
      },
      "outputs": [],
      "source": [
        "fake_df.drop(columns=['date','subject'],inplace=True)\n",
        "true_df.drop(columns=['date','subject'],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ca15b2b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ca15b2b",
        "outputId": "efd704a3-cdd9-4ddd-b3fe-f35c39cf438c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined dataset shape: (18700, 3)\n",
            "Sample of the combined and shuffled data:\n",
            "                                               title  \\\n",
            "0   Trump National Security Pick Monica Crowley’s...   \n",
            "1  Merkel heads to EU-Africa summit with eye on m...   \n",
            "2  After U.S. veto, U.N. General Assembly to meet...   \n",
            "3  New York mayor criticized for proposed limits ...   \n",
            "4  Trump meets insurers, promises catastrophic ye...   \n",
            "\n",
            "                                                text  label  \n",
            "0  Conservative columnist Monica Crowley is set f...      1  \n",
            "1  BERLIN (Reuters) - German Chancellor Angela Me...      0  \n",
            "2  UNITED NATIONS (Reuters) - The 193-member Unit...      0  \n",
            "3  NEW YORK (Reuters) - New York City public defe...      0  \n",
            "4  WASHINGTON (Reuters) - President Donald Trump ...      0  \n"
          ]
        }
      ],
      "source": [
        "# Combine the two DataFrames\n",
        "combined_df = pd.concat([fake_df, true_df], ignore_index=True)\n",
        "\n",
        "# Shuffle the combined DataFrame randomly\n",
        "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(f\"Combined dataset shape: {combined_df.shape}\")\n",
        "print(\"Sample of the combined and shuffled data:\")\n",
        "print(combined_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training\n"
      ],
      "metadata": {
        "id": "egxFVTRuKUV-"
      },
      "id": "egxFVTRuKUV-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72d96212",
      "metadata": {
        "id": "72d96212"
      },
      "outputs": [],
      "source": [
        "# Feature Combination: Create 'full_text' column\n",
        "combined_df['full_text'] = combined_df['title'] + ' ' + combined_df['text']\n",
        "\n",
        "# Data Split: Separate features and targets\n",
        "X = combined_df['full_text']\n",
        "y = combined_df['label']\n",
        "\n",
        "# Split into train and test sets (80% train, 20% test)\n",
        "# Stratified split based on label with random_state=42\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Initialize Tokenizer for 'bert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize training data\n",
        "train_encodings = tokenizer(\n",
        "    X_train.tolist(),\n",
        "    max_length=256,\n",
        "    padding='max_length',\n",
        "    truncation=True,\n",
        "    return_tensors='tf'\n",
        ")\n",
        "\n",
        "# Tokenize testing data\n",
        "test_encodings = tokenizer(\n",
        "    X_test.tolist(),\n",
        "    max_length=256,\n",
        "    padding='max_length',\n",
        "    truncation=True,\n",
        "    return_tensors='tf'\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Model\n"
      ],
      "metadata": {
        "id": "e1irPrjMKjcM"
      },
      "id": "e1irPrjMKjcM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_-1zbVv7I66l",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696,
          "referenced_widgets": [
            "474b4d1591834044bdb767667e4ae713",
            "4aac8acacebf450398d2f9618c6d226d",
            "53247bc2b1064ddeb5d53a2fa06677fd",
            "663ad2df919944579f47f390ed35da66",
            "d5580add4dec4dcf8cef6b64a31f06d6",
            "0caa86a9a2c449109e45aa7751af73ac",
            "b4bee70b65a840cbaf0ad385534d39c2",
            "e4f76f9bb88740eb8edebc58b1d953f1",
            "cccd368cf1a14330bce35cd5938e1d16",
            "06aa9c7d10dd45b1b9ddae55de791ff6",
            "457485f064a947f1afded4de9b10a812"
          ]
        },
        "id": "_-1zbVv7I66l",
        "outputId": "d676ce21-351f-42e6-9789-10072e7e98b6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tf_model.h5:   0%|          | 0.00/536M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "474b4d1591834044bdb767667e4ae713"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT Functional Model successfully defined.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ attention_mask      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_ids           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bert_wrapper        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ attention_mask[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBertWrapper\u001b[0m)       │                   │            │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_layer       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bert_wrapper[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output_layer        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m769\u001b[0m │ dropout_layer[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ attention_mask      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_ids           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bert_wrapper        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertWrapper</span>)       │                   │            │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_layer       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bert_wrapper[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output_layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">769</span> │ dropout_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m769\u001b[0m (3.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">769</span> (3.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m769\u001b[0m (3.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">769</span> (3.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 377ms/step - accuracy: 0.7975 - loss: 0.4764 - val_accuracy: 0.8203 - val_loss: 0.3660\n",
            "Epoch 2/3\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 343ms/step - accuracy: 0.8405 - loss: 0.3556 - val_accuracy: 0.8861 - val_loss: 0.2915\n",
            "Epoch 3/3\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 343ms/step - accuracy: 0.8848 - loss: 0.2935 - val_accuracy: 0.9182 - val_loss: 0.2403\n",
            "\n",
            "Model trained and saved as 'bert_fakenews_model' (SavedModel format)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from transformers import TFBertModel\n",
        "\n",
        "# Define a custom Keras Layer to wrap the TFBertModel\n",
        "class BertWrapper(tf.keras.layers.Layer):\n",
        "    def __init__(self, bert_model=None, **kwargs):\n",
        "        super(BertWrapper, self).__init__(**kwargs)\n",
        "        # bert_model can be None when loading from config\n",
        "        self.bert = bert_model\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_ids = inputs['input_ids']\n",
        "        attention_mask = inputs['attention_mask']\n",
        "        # Pass training=False to keep BERT layers in inference mode during functional API construction\n",
        "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask, training=self.trainable)\n",
        "        cls_embedding = bert_output.last_hidden_state[:, 0, :]\n",
        "        return cls_embedding\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(BertWrapper, self).get_config()\n",
        "        # Don't serialize bert_model, it will be loaded separately\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        # Load BERT model when reconstructing from config\n",
        "        bert_model = TFBertModel.from_pretrained('bert-base-uncased', use_safetensors=False)\n",
        "        return cls(bert_model=bert_model, **config)\n",
        "\n",
        "# --- 1. Load the Base BERT Encoder ---\n",
        "# Load the pre-trained BERT model (only the encoder/feature extractor)\n",
        "bert_base_model = TFBertModel.from_pretrained('bert-base-uncased', use_safetensors=False)\n",
        "\n",
        "# Instantiate the wrapper\n",
        "bert_encoder = BertWrapper(bert_base_model)\n",
        "\n",
        "# --- 2. Define Inputs ---\n",
        "# Define the two required Input layers for BERT\n",
        "# The shape must match the max_length (256) used in tokenization\n",
        "input_ids = Input(shape=(256,), dtype=tf.int32, name='input_ids')\n",
        "attention_mask = Input(shape=(256,), dtype=tf.int32, name='attention_mask')\n",
        "\n",
        "# Create a dictionary to feed the inputs into the BERT wrapper layer\n",
        "model_inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
        "\n",
        "# --- 3. Pass Inputs Through BERT Wrapper ---\n",
        "# Pass the inputs through the custom BERT wrapper layer\n",
        "pooled_output = bert_encoder(model_inputs)\n",
        "\n",
        "# --- 4. Build Custom Classification Head ---\n",
        "# Add a Dropout layer for regularization\n",
        "x = Dropout(0.2, name='dropout_layer')(pooled_output)\n",
        "\n",
        "# Add the final Dense layer for classification\n",
        "# Output shape is 1, and 'sigmoid' activation for binary classification\n",
        "output = Dense(1, activation='sigmoid', name='output_layer')(x)\n",
        "\n",
        "# --- 5. Create the Final Keras Model Object ---\n",
        "model = Model(inputs=[input_ids, attention_mask], outputs=output)\n",
        "print(\"BERT Functional Model successfully defined.\")\n",
        "\n",
        "\n",
        "# --- 6. Model Compilation ---\n",
        "# Define the Adam optimizer with a low learning rate for fine-tuning\n",
        "optimizer = Adam(learning_rate=3e-5)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='binary_crossentropy',  # Standard loss for binary classification\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Display the model summary (optional, but helpful)\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# --- 7. Model Training ---\n",
        "# Fit the model to the training data\n",
        "\n",
        "# Extract the tensors from the tokenized objects\n",
        "X_train_inputs = {'input_ids': train_encodings['input_ids'],\n",
        "                  'attention_mask': train_encodings['attention_mask']}\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_inputs,\n",
        "    y_train,\n",
        "    validation_data=(\n",
        "        {'input_ids': test_encodings['input_ids'],\n",
        "         'attention_mask': test_encodings['attention_mask']},\n",
        "        y_test\n",
        "    ),\n",
        "    batch_size=16, # Batch size should be a power of 2 (16, 32, 64)\n",
        "    epochs=3       # Typically 2-4 epochs are enough for fine-tuning BERT\n",
        ")\n",
        "\n",
        "# --- 8. Save the Model ---\n",
        "# Use SavedModel format which handles custom objects better\n",
        "model.save('bert_fakenews_model.keras')\n",
        "print(\"\\nModel trained and saved as 'bert_fakenews_model' (SavedModel format)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the model"
      ],
      "metadata": {
        "id": "-4e_vg24KoFn"
      },
      "id": "-4e_vg24KoFn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3d3363c",
      "metadata": {
        "id": "f3d3363c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "dabe758d-aa33-45fb-f800-0646c403ca7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading tokenizer...\n",
            "Loading trained model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ attention_mask      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_ids           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bert_wrapper        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ attention_mask[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBertWrapper\u001b[0m)       │                   │            │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_layer       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bert_wrapper[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output_layer        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m769\u001b[0m │ dropout_layer[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ attention_mask      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_ids           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bert_wrapper        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertWrapper</span>)       │                   │            │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_layer       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bert_wrapper[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output_layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">769</span> │ dropout_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,309\u001b[0m (9.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,309</span> (9.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m769\u001b[0m (3.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">769</span> (3.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,540\u001b[0m (6.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,540</span> (6.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- TEST RESULTS ----\n",
            "REAL (0.4614)  ->  Breaking: Aliens landed in Mumbai last night\n",
            "REAL (0.2521)  ->  The Prime Minister addressed the nation today\n",
            "FAKE (0.5046)  ->  Drinking hot water cures all diseases, doctors say\n",
            "REAL (0.1012)  ->  The stock market closed higher after RBI announcement\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFBertModel\n",
        "\n",
        "# -----------------------------\n",
        "# 1. CUSTOM BERT WRAPPER\n",
        "# (MUST MATCH TRAINING)\n",
        "# -----------------------------\n",
        "class BertWrapper(tf.keras.layers.Layer):\n",
        "    def __init__(self, bert_model=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.bert = bert_model\n",
        "\n",
        "    def call(self, inputs):\n",
        "        outputs = self.bert(\n",
        "            input_ids=inputs['input_ids'],\n",
        "            attention_mask=inputs['attention_mask'],\n",
        "            training=False  # inference mode\n",
        "        )\n",
        "        # CLS token\n",
        "        return outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "    def get_config(self):\n",
        "        return super().get_config()\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        bert_model = TFBertModel.from_pretrained(\n",
        "            'bert-base-uncased',\n",
        "            use_safetensors=False\n",
        "        )\n",
        "        return cls(bert_model=bert_model, **config)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 2. LOAD TOKENIZER\n",
        "# -----------------------------\n",
        "print(\"Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 3. LOAD SAVED MODEL\n",
        "# -----------------------------\n",
        "print(\"Loading trained model...\")\n",
        "model = tf.keras.models.load_model(\n",
        "    \"bert_fakenews_model.keras\",\n",
        "    custom_objects={\n",
        "        \"BertWrapper\": BertWrapper,\n",
        "        \"TFBertModel\": TFBertModel\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"Model loaded successfully!\\n\")\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 4. PREDICTION FUNCTION\n",
        "# -----------------------------\n",
        "def predict_news(text):\n",
        "    encodings = tokenizer(\n",
        "        text,\n",
        "        max_length=256,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"tf\"\n",
        "    )\n",
        "\n",
        "    inputs = {\n",
        "        \"input_ids\": encodings[\"input_ids\"],\n",
        "        \"attention_mask\": encodings[\"attention_mask\"]\n",
        "    }\n",
        "\n",
        "    prediction = model.predict(inputs, verbose=0)\n",
        "    prob_fake = float(prediction[0][0])\n",
        "\n",
        "    label = \"FAKE\" if prob_fake >= 0.5 else \"REAL\"\n",
        "    return prob_fake, label\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 5. TEST WITH SAMPLE TEXTS\n",
        "# -----------------------------\n",
        "test_samples = [\n",
        "    \"Breaking: Aliens landed in Mumbai last night\",\n",
        "    \"The Prime Minister addressed the nation today\",\n",
        "    \"Drinking hot water cures all diseases, doctors say\",\n",
        "    \"The stock market closed higher after RBI announcement\"\n",
        "]\n",
        "\n",
        "print(\"---- TEST RESULTS ----\")\n",
        "for text in test_samples:\n",
        "    prob, label = predict_news(text)\n",
        "    print(f\"{label} ({prob:.4f})  ->  {text}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"bert_fakenews_model.keras\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "DnC86KVN_CR2",
        "outputId": "f3d1bb6f-b35c-4b53-924b-50d66232050b"
      },
      "id": "DnC86KVN_CR2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3d5ea7e9-3dc9-47aa-bdab-edfdefd4e730\", \"bert_fakenews_model.keras\", 34152)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.version)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgsaYeGQPRHj",
        "outputId": "03b3a305-c21b-40b1-dff3-b462f1ac1489"
      },
      "id": "FgsaYeGQPRHj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip show tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwVUNOM4T-vB",
        "outputId": "a7e1edb3-f749-4d46-a45e-e8214e8775a4"
      },
      "id": "AwVUNOM4T-vB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.19.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, termcolor, typing-extensions, wrapt\n",
            "Required-by: dopamine_rl, tensorflow-text, tensorflow_decision_forests, tf_keras\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "474b4d1591834044bdb767667e4ae713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4aac8acacebf450398d2f9618c6d226d",
              "IPY_MODEL_53247bc2b1064ddeb5d53a2fa06677fd",
              "IPY_MODEL_663ad2df919944579f47f390ed35da66"
            ],
            "layout": "IPY_MODEL_d5580add4dec4dcf8cef6b64a31f06d6"
          }
        },
        "4aac8acacebf450398d2f9618c6d226d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0caa86a9a2c449109e45aa7751af73ac",
            "placeholder": "​",
            "style": "IPY_MODEL_b4bee70b65a840cbaf0ad385534d39c2",
            "value": "tf_model.h5: 100%"
          }
        },
        "53247bc2b1064ddeb5d53a2fa06677fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4f76f9bb88740eb8edebc58b1d953f1",
            "max": 536063208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cccd368cf1a14330bce35cd5938e1d16",
            "value": 536063208
          }
        },
        "663ad2df919944579f47f390ed35da66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06aa9c7d10dd45b1b9ddae55de791ff6",
            "placeholder": "​",
            "style": "IPY_MODEL_457485f064a947f1afded4de9b10a812",
            "value": " 536M/536M [00:06&lt;00:00, 63.3MB/s]"
          }
        },
        "d5580add4dec4dcf8cef6b64a31f06d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0caa86a9a2c449109e45aa7751af73ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4bee70b65a840cbaf0ad385534d39c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4f76f9bb88740eb8edebc58b1d953f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cccd368cf1a14330bce35cd5938e1d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06aa9c7d10dd45b1b9ddae55de791ff6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "457485f064a947f1afded4de9b10a812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}